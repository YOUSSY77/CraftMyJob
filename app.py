# -*- coding: utf-8 -*-
import os
# ‚îÄ‚îÄ 0) On retire tout proxy du contexte
for v in ("HTTP_PROXY","http_proxy","HTTPS_PROXY","https_proxy"):
    os.environ.pop(v, None)

import streamlit as st
import requests
from PyPDF2 import PdfReader
from docx import Document
import io
from fpdf import FPDF
import pandas as pd
import re
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

# ‚îÄ‚îÄ Page config
st.set_page_config(
    page_title="CraftMyJob ‚Äì by Job Seekers Hub France",
    layout="centered"
)
st.title("‚ú® CraftMyJob")
st.caption("by Job Seekers Hub France üá´üá∑")

# ‚îÄ‚îÄ 1) Chargement du r√©f√©rentiel m√©tiers pour SIS
@st.cache_data
def load_metiers() -> pd.DataFrame:
    return pd.read_csv("referentiel_metiers_craftmyjob_final.csv", dtype=str)

df_metiers = load_metiers()

# ‚îÄ‚îÄ 2) Construction TF-IDF pour matching m√©tier
@st.cache_data
def build_tfidf(df: pd.DataFrame):
    corpus = (
        df["Activites"].fillna("") + " " +
        df["Competences"].fillna("") + " " +
        df["Metier"].fillna("")
    ).tolist()
    vect = TfidfVectorizer(max_features=2000)
    X_ref = vect.fit_transform(corpus)
    return vect, X_ref

vect, X_ref = build_tfidf(df_metiers)

# ‚îÄ‚îÄ UTILITAIRES ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

def get_gpt_response(prompt: str, api_key: str) -> str:
    url = "https://api.openai.com/v1/chat/completions"
    headers = {
        "Authorization": f"Bearer {api_key}",
        "Content-Type":  "application/json"
    }
    payload = {
        "model": "gpt-3.5-turbo",
        "messages": [
            {"role":"system","content":"Tu es un expert en recrutement et en personal branding."},
            {"role":"user",  "content":prompt}
        ],
        "temperature":0.7,
        "max_tokens":800
    }
    r = requests.post(url, json=payload, headers=headers, timeout=30)
    r.raise_for_status()
    return r.json()["choices"][0]["message"]["content"]

class PDFGen:
    @staticmethod
    def to_pdf(text: str) -> io.BytesIO:
        buf = io.BytesIO()
        pdf = FPDF()
        pdf.add_page()
        pdf.set_font("Arial", size=12)
        for line in text.split("\n"):
            pdf.multi_cell(0, 8, line)
        pdf.output(buf)
        buf.seek(0)
        return buf

def fetch_ft_token(cid: str, sec: str) -> str:
    auth_url = (
        "https://entreprise.pole-emploi.fr"
        "/connexion/oauth2/access_token?realm=/partenaire"
    )
    data = {
        "grant_type":"client_credentials",
        "client_id":cid,
        "client_secret":sec,
        "scope":"api_offresdemploiv2 o2dsoffre"
    }
    r = requests.post(auth_url, data=data, timeout=10)
    r.raise_for_status()
    return r.json()["access_token"]

def search_offres(token: str, mots: str, loc: str, limit: int = 5) -> list:
    url = (
        "https://api.francetravail.io"
        "/partenaire/offresdemploi/v2/offres/search"
    )
    headers = {"Authorization": f"Bearer {token}"}
    params  = {"motsCles": mots, "localisation": loc, "range": f"0-{limit-1}"}
    r = requests.get(url, headers=headers, params=params, timeout=10)
    if r.status_code == 204:
        return []
    if r.status_code not in (200, 206):
        st.error(f"FT API {r.status_code} : {r.text}")
        return []
    return r.json().get("resultats", [])

def scorer_metier(inp: dict, df: pd.DataFrame, top_k: int = 6) -> pd.DataFrame:
    user_doc = " ".join([inp["missions"], inp["skills"], inp["job_title"]])
    v_user   = vect.transform([user_doc])
    cosines  = cosine_similarity(v_user, X_ref).flatten()
    df2      = df.copy()
    df2["score"] = (cosines * 100).round(1)
    return df2.nlargest(top_k, "score")

# ‚îÄ‚îÄ Autocompl√©tion via Geo API du Gouvernement ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
def search_communes(query: str, limit: int = 10) -> list[str]:
    url = "https://geo.api.gouv.fr/communes"
    params = {
        "nom":    query,
        "fields": "nom,codesPostaux",
        "boost":  "population",
        "limit":  limit
    }
    r = requests.get(url, params=params, timeout=5)
    r.raise_for_status()
    r√©sultats = []
    for c in r.json():
        cp = c["codesPostaux"][0] if c["codesPostaux"] else "00000"
        r√©sultats.append(f"{c['nom']} ({cp})")
    return r√©sultats

# ‚îÄ‚îÄ 1Ô∏è‚É£ Que souhaites-tu faire dans la vie ?
st.header("1Ô∏è‚É£ Que souhaites-tu faire dans la vie ?")
uploaded_cv = st.file_uploader("üìÇ Optionnel : ton CV", type=["pdf","docx","txt"])
cv_text = ""
if uploaded_cv:
    ext = uploaded_cv.name.rsplit(".",1)[-1].lower()
    if ext=="pdf":
        cv_text = " ".join(p.extract_text() or "" for p in PdfReader(uploaded_cv).pages)
    elif ext=="docx":
        cv_text = " ".join(p.text for p in Document(uploaded_cv).paragraphs)
    else:
        cv_text = uploaded_cv.read().decode()

job_title = st.text_input("üî§ Intitul√© du poste souhait√©")
missions  = st.text_area("üìã Missions principales")
values    = st.text_area("üè¢ Valeurs (facultatif)")
skills    = st.text_area("üß† Comp√©tences cl√©s")

# Autocompl√©tion multi-villes
typed = st.text_input("üìç Commencez √† taper une ville‚Ä¶")
# on r√©cup√®re les suggestions de l'API GOV
raw_suggestions = search_communes(typed) if typed else []
# on conserve aussi les villes d√©j√† s√©lectionn√©es pour ne pas les perdre
all_suggestions = list(dict.fromkeys(locations + raw_suggestions))
locations = st.multiselect(
    "S√©lectionnez une ou plusieurs villes",
    options=all_suggestions,
    default=locations
)
# extraction des codes postaux
postal_codes = [
    m.group(1)
    for loc in locations
    if (m := re.search(r"\((\d{5})\)", loc))
]


# Extraction des codes postaux
postal_codes = [
    m.group(1)
    for loc in locations
    if (m := re.search(r"\((\d{5})\)", loc))
]

experience_level = st.radio("üéØ Niveau d'exp√©rience", ["D√©butant(e)","Exp√©riment√©(e)","Senior"])
contract_type    = st.selectbox("üìÑ Type de contrat", ["CDI","Freelance","CDD","Stage"])
remote           = st.checkbox("üè† Full remote")

# ‚îÄ‚îÄ 2Ô∏è‚É£ Tes cl√©s API
st.header("2Ô∏è‚É£ Tes cl√©s API")
openai_key   = st.text_input("üîë OpenAI API Key", type="password")
ft_client_id = st.text_input("üîë P√¥le-Emploi Client ID", type="password")
ft_secret    = st.text_input("üîë P√¥le-Emploi Client Secret", type="password")

# ‚îÄ‚îÄ 3Ô∏è‚É£ G√©n√©rations IA
st.header("3Ô∏è‚É£ G√©n√©rations IA")
templates = {
    "üìÑ Bio LinkedIn":          "R√©dige une bio LinkedIn engageante et professionnelle.",
    "‚úâÔ∏è Mail de candidature":   "√âcris un mail de candidature spontan√©e clair et convaincant.",
    "üìÉ Mini CV":               "G√©n√®re un mini-CV (5-7 lignes), souligne deux mots-cl√©s.",
    "üß© CV optimis√© IA":        "R√©dige un CV optimis√©, souligne deux mots-cl√©s."
}
choices = st.multiselect("Choisis ce que tu veux g√©n√©rer", list(templates), default=list(templates)[:2])

def generate_prompt(label: str, inp: dict, cv: str) -> str:
    base = (
        f"Poste: {inp['job_title']}\n"
        f"Missions: {inp['missions']}\n"
        f"Comp√©tences: {inp['skills']}\n"
        f"Valeurs: {inp['values']}\n"
        f"Localisation: {', '.join(inp['locations'])}\n"
        f"Exp√©rience: {inp['experience_level']}\n"
        f"Contrat: {inp['contract_type']}\n"
        f"T√©l√©travail: {'Oui' if inp['remote'] else 'Non'}\n"
    )
    if cv:
        base += f"CV extrait: {cv[:300]}...\n"
    return base + "\n" + templates[label]

# ‚îÄ‚îÄ 4Ô∏è‚É£ Matching & Offres
st.header("4Ô∏è‚É£ Matching & Offres")

if st.button("üöÄ Lancer tout"):
    #  validations OpenAI
    if not openai_key:
        st.error("üîë Cl√© OpenAI requise"); st.stop()

    inp = {
        "job_title": job_title,
        "missions":  missions,
        "values":    values,
        "skills":    skills,
        "locations": locations,
        "experience_level": experience_level,
        "contract_type":    contract_type,
        "remote":           remote
    }

    # ‚Äî IA (toujours)
    for lbl in choices:
        try:
            out = get_gpt_response(generate_prompt(lbl, inp, cv_text), openai_key)
            st.subheader(lbl)
            st.markdown(out)
            if lbl == "üß© CV optimis√© IA":
                pdf = PDFGen.to_pdf(out)
                st.download_button("üì• T√©l√©charger PDF", data=pdf,
                                   file_name="CV_optimise.pdf", mime="application/pdf")
        except Exception as e:
            st.error(f"‚ùå Erreur IA ({lbl}) : {e}")

    # ‚Äî Offres France-Travail (si identifiants + villes)
    if ft_client_id and ft_secret and postal_codes:
        token = fetch_ft_token(ft_client_id, ft_secret)
        st.subheader(f"üîé Top 5 offres pour ¬´ {job_title} ¬ª")
        mots = f"{job_title} {skills}"
        offres_all = []
        for cp in postal_codes:
            offres_all += search_offres(token, mots, cp, limit=5)
        # d√©duplication
        seen, uniq = set(), []
        for o in offres_all:
            url = o.get("contact",{}).get("urlOrigine","")
            if url and url not in seen:
                seen.add(url); uniq.append(o)
        if uniq:
            for o in uniq[:5]:
                st.markdown(f"**{o['intitule']}** ‚Äì {o['lieuTravail']['libelle']}  \n[Voir]({o['contact']['urlOrigine']})\n---")
        else:
            st.info("üîç Aucune offre trouv√©e pour ce poste.")
    else:
        st.warning("‚ö†Ô∏è Pour voir les offres, renseigne tes identifiants P√¥le-Emploi et au moins une ville.")

    # ‚Äî SIS : Top 6 m√©tiers + Top 3 offres par m√©tier
st.subheader("üß† SIS ‚Äì Les m√©tiers qui te correspondent")
top6 = scorer_metier(inp, df_metiers, top_k=6)

for _, r in top6.iterrows():
    st.markdown(f"**{r['Metier']}** ‚Äì {int(r['score'])}%")
    # on collecte les offres de toutes les villes s√©lectionn√©es
    subs_all = []
    for cp in postal_codes:
        subs_all += search_offres(token, r["Metier"], cp, limit=3)
    # on d√©duplique par URL
    seen2, uniq2 = set(), []
    for o in subs_all:
        url2 = o.get("contact",{}).get("urlPostulation") or o.get("contact",{}).get("urlOrigine","")
        if url2 and url2 not in seen2:
            seen2.add(url2)
            uniq2.append(o)
    if uniq2:
        for o in uniq2[:3]:
            date = o.get("dateCreation","‚Äî")[:10]
            lien = o.get("contact",{}).get("urlPostulation") or o.get("contact",{}).get("urlOrigine","#")
            desc = o.get("description","").replace("\n"," ")[:150] + "‚Ä¶"
            st.markdown(
                f"‚Ä¢ **{o['intitule']}**  \n"
                f"  _Publi√© le {date}_  \n"
                f"  {desc}  \n"
                f"  [Voir / Postuler]({lien})"
            )
    else:
        st.info("  ‚Ä¢ Aucune offre trouv√©e pour ce m√©tier dans les villes s√©lectionn√©es.")
